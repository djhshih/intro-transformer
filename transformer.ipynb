{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8fddec35-83d0-4322-8048-3052c0b523d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as fn\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f598349-4197-492f-8455-ac2dfc30bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3621cc0-f0b9-45a3-bf66-c7e27045056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96476324-cbfc-4923-9649-2bb812ede07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self, context_size, batch_size):\n",
    "        self.n_layer = 1\n",
    "        self.n_head = 4\n",
    "        self.embed_size = 8\n",
    "        self.context_size = context_size\n",
    "        self.batch_size = batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bc309ff8-e957-4a04-b038-68aa48e2d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    context_size = 16,\n",
    "    batch_size = 64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e79119a-826c-461a-b3e4-76243559d20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.preprocess' from '/home/davids/projects/intro-transformer/utils/preprocess.py'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils.preprocess as pp\n",
    "reload(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "181deb69-f140-4d09-92f8-796583adb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pp.ShortSequenceDataset('data/restriction-sites.txt', device,\n",
    "    context_size=config.context_size, batch_size=config.batch_size)\n",
    "config.vocab_size = len(dataset.vocab)\n",
    "config.init_code = dataset.init_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d28c037c-e60d-4ee3-9029-42e9e05e32d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[30, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15,  4, 17, 19, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 15, 19, 17, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 26,  4, 15, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,  4, 15, 15, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 26,  4, 15, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,  4, 15, 15, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 17, 15, 26, 19, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 17, 17, 19, 19, 26],\n",
       "         [30, 30, 30, 30, 30, 15, 17, 17, 26, 19, 17,  1,  9,  4, 13,  2],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 17, 17, 28, 19, 19, 26]]),\n",
       " tensor([[30, 30, 30, 30, 30, 30, 30, 30, 15, 15,  4, 17, 19, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 15, 19, 17, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 26,  4, 15, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 30,  4, 15, 15, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 26,  4, 15, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 30,  4, 15, 15, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 17, 15, 26, 19, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 17, 17, 19, 19, 26,  0],\n",
       "         [30, 30, 30, 30, 15, 17, 17, 26, 19, 17,  1,  9,  4, 13,  2,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 15,  4, 17, 17, 28, 19, 19, 26,  0]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3c1b7577-c8a7-4dde-95d4-07278277f1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('^^^^^^^^^A/CCGGT', '^^^^^^^^A/CCGGT$')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( dataset.decode(dataset[7][0]), dataset.decode(dataset[7][1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ece3921d-f419-45be-accc-acc0282bd2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d947af17-5333-47c6-ad95-abad303cd93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[30, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15,  4, 17, 19, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 15, 19, 17, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 26,  4, 15, 26, 26]]),\n",
       " tensor([[30, 30, 30, 30, 30, 30, 30, 30, 15, 15,  4, 17, 19, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 15, 19, 17, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 26,  4, 15, 26, 26,  0]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e3913bc-c6b1-4e5c-8d0f-51284a276dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed = nn.Embedding(config.vocab_size, config.embed_size)\n",
    "        self.unembed = nn.Linear(config.embed_size, config.vocab_size)\n",
    "\n",
    "    def forward(self, X, Y=None):\n",
    "        # X is (B, T), Y is (B, T)\n",
    "        \n",
    "        embeds = self.embed(X)  # (B, T, D)\n",
    "        logits = self.unembed(embeds)  # (B, T, C)\n",
    "\n",
    "        if Y is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            Y = Y.view(B*T)\n",
    "            loss = fn.cross_entropy(logits, Y)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, n, X=None, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Generate n new token codes given context X.\n",
    "        \"\"\"\n",
    "        if X is None:\n",
    "            X = torch.tensor([[config.init_code]])\n",
    "        for _ in range(n):\n",
    "            if X.size(1) > self.config.context_size:\n",
    "                # sequence context is too long; crop it to context_size\n",
    "                X_cropped = X[:, -self.config.context_size:]\n",
    "            else:\n",
    "                X_cropped = X\n",
    "            # get prediction\n",
    "            logits, _ = self(X_cropped)\n",
    "            # get last time step and scale by temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            probs = fn.softmax(logits, dim=1)  # (B, C)\n",
    "            x_new = torch.multinomial(probs, num_samples=1)\n",
    "            X = torch.cat((X, x_new), dim=1)   # (B, T+1)\n",
    "        return X[0, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "710498e1-202f-4ebc-bdb0-a7b77a7bcd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7275, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT(config).to(device)\n",
    "batch = dataset[0:3]\n",
    "logits, loss = model(batch[0], batch[1])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af0b0677-1c22-4e76-9031-b05949807a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'^GGAG/)$A'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.decode( model.sample(8) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cbdb7412-4a55-4d4c-af32-a9126a63f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "498c75ee-be50-4217-983c-2be18d3923a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.52it/s]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for step, batch in enumerate(dataset.loader):\n",
    "        X, Y = batch\n",
    "        # evaluate loss\n",
    "        logits, loss = model(X, Y)\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "787a7ca1-0106-4ab5-ada4-c6d8f94cef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6972150802612305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'^^^C$/TGT'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(loss.item())\n",
    "dataset.decode( model.sample(8) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12044ac6-df3d-4d08-8db3-7f2dfa0f7837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
