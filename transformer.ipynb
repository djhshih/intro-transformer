{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "8fddec35-83d0-4322-8048-3052c0b523d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as fn\n",
    "import math\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "3f598349-4197-492f-8455-ac2dfc30bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "f3621cc0-f0b9-45a3-bf66-c7e27045056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "96476324-cbfc-4923-9649-2bb812ede07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self, context_size, batch_size):\n",
    "        self.n_layers = 1\n",
    "        self.n_heads = 4\n",
    "        self.embed_size = 8\n",
    "        self.context_size = context_size\n",
    "        self.batch_size = batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "bc309ff8-e957-4a04-b038-68aa48e2d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    context_size = 16,\n",
    "    batch_size = 64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5e79119a-826c-461a-b3e4-76243559d20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.preprocess' from '/home/davids/projects/intro-transformer/utils/preprocess.py'>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils.preprocess as pp\n",
    "reload(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "181deb69-f140-4d09-92f8-796583adb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pp.ShortSequenceDataset('data/restriction-sites.txt', device,\n",
    "    context_size=config.context_size, batch_size=config.batch_size)\n",
    "config.vocab_size = len(dataset.vocab)\n",
    "config.init_code = dataset.init_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d28c037c-e60d-4ee3-9029-42e9e05e32d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[30, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15,  4, 17, 19, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 15, 19, 17, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 26,  4, 15, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,  4, 15, 15, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 26,  4, 15, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,  4, 15, 15, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 17, 15, 26, 19, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 17, 17, 19, 19, 26],\n",
       "         [30, 30, 30, 30, 30, 15, 17, 17, 26, 19, 17,  1,  9,  4, 13,  2],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 17, 17, 28, 19, 19, 26]]),\n",
       " tensor([[30, 30, 30, 30, 30, 30, 30, 30, 15, 15,  4, 17, 19, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 15, 19, 17, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 26,  4, 15, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 30,  4, 15, 15, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 26,  4, 15, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 30,  4, 15, 15, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 17, 15, 26, 19, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 17, 17, 19, 19, 26,  0],\n",
       "         [30, 30, 30, 30, 15, 17, 17, 26, 19, 17,  1,  9,  4, 13,  2,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 15,  4, 17, 17, 28, 19, 19, 26,  0]]))"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "3c1b7577-c8a7-4dde-95d4-07278277f1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('^^^^^^^^^A/CCGGT', '^^^^^^^^A/CCGGT$')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( dataset.decode(dataset[7][0]), dataset.decode(dataset[7][1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ece3921d-f419-45be-accc-acc0282bd2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "d947af17-5333-47c6-ad95-abad303cd93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[30, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15,  4, 17, 19, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 15, 19, 17, 26, 26],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 26,  4, 15, 26, 26]]),\n",
       " tensor([[30, 30, 30, 30, 30, 30, 30, 30, 15, 15,  4, 17, 19, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15,  4, 15, 19, 17, 26, 26,  0],\n",
       "         [30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 26,  4, 15, 26, 26,  0]]))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b5469e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        embed_size = config.embed_size\n",
    "        context_size = config.context_size\n",
    "        # key, query, value projecions for all attention heads\n",
    "        self.kqv = nn.Linear(embed_size, 3*embed_size, bias=False)\n",
    "        # output projection\n",
    "        self.output = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        # mask out upper diagonal\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(context_size, context_size))\n",
    "            .view(1, 1, context_size, context_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # batch size, sequence length, and embedding dimensionality\n",
    "        B, T, D = X.shape\n",
    "\n",
    "        embed_size = self.config.embed_size\n",
    "        n_heads = self.config.n_heads\n",
    "\n",
    "        # (B, D, 3*D)  -> (B, D, D)\n",
    "        # multiple each weight matrix with data and split\n",
    "        query, key, value = self.kqv(X).split(embed_size, dim=2)\n",
    "        # (B, D, D) -> (B, H, T, D/H)\n",
    "        key = key.view(B, T, n_heads, D // n_heads).transpose(1, 2)  \n",
    "        query = query.view(B, T, n_heads, D // n_heads).transpose(1, 2)  \n",
    "        value = value.view(B, T, n_heads, D // n_heads).transpose(1, 2)  \n",
    "\n",
    "        # (B, H, T, D/H) @ (B, H, D/H, T) -> (B, H, T, T)\n",
    "        att = (query @ key.transpose(-2, -1)) / math.sqrt(key.size(-1))\n",
    "        att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float('-inf'))\n",
    "        att = fn.softmax(att, dim=-1)\n",
    "\n",
    "        # (B, H, T, T) @ (B, H, T, D/H) -> (B, H, T, D/H)\n",
    "        Y = att @ value\n",
    "\n",
    "        # re-assemble outputs from all heads\n",
    "        Y = Y.transpose(1, 2).contiguous().view(B, T, D)\n",
    "\n",
    "        # linear map of all heads together\n",
    "        Y = self.output(Y)\n",
    "        return Y\n",
    "\n",
    "class Feedforward(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        embed_size = config.embed_size\n",
    "        self.hidden1 = nn.Linear(embed_size, 4*embed_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.hidden2 = nn.Linear(4*embed_size, embed_size)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.hidden1(X)\n",
    "        X = self.gelu(X)\n",
    "        X = self.hidden2(X)\n",
    "        return X\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attend = AttentionHead(config)\n",
    "        self.feed = Feedforward(config)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.attend(X)\n",
    "        X = X + self.feed(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "7e3913bc-c6b1-4e5c-8d0f-51284a276dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.token_embed = nn.Embedding(config.vocab_size, config.embed_size)\n",
    "        self.pos_embed = nn.Embedding(config.context_size, config.embed_size)\n",
    "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.n_layers)])\n",
    "        self.unembed = nn.Linear(config.embed_size, config.vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, X, Y=None):\n",
    "        # X is (B, T), Y is (B, T)\n",
    "        pos = torch.arange(0, X.shape[1], dtype=torch.long)\n",
    "        \n",
    "        token_embeds = self.token_embed(X)  # (B, T, D)\n",
    "        pos_embeds = self.pos_embed(pos)    # (B, T, D)\n",
    "        embeds = token_embeds + pos_embeds\n",
    "\n",
    "        for block in self.blocks:\n",
    "            embeds = block(embeds)\n",
    "\n",
    "        logits = self.unembed(embeds)  # (B, T, C)\n",
    "\n",
    "        # tie the unembedding weights to the embedding weights\n",
    "        # linear function transposes the weight\n",
    "        #logits = fn.linear(embeds, self.token_embed.weight)\n",
    "\n",
    "        if Y is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            Y = Y.view(B*T)\n",
    "            loss = fn.cross_entropy(logits, Y)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, n, X=None, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Generate n new token codes given context X.\n",
    "        \"\"\"\n",
    "        if X is None:\n",
    "            X = torch.tensor([[config.init_code]])\n",
    "        for _ in range(n):\n",
    "            if X.size(1) > self.config.context_size:\n",
    "                # sequence context is too long; crop it to context_size\n",
    "                X_cropped = X[:, -self.config.context_size:]\n",
    "            else:\n",
    "                X_cropped = X\n",
    "            # get prediction\n",
    "            logits, _ = self(X_cropped)\n",
    "            # get last time step and scale by temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            probs = fn.softmax(logits, dim=1)  # (B, C)\n",
    "            x_new = torch.multinomial(probs, num_samples=1)\n",
    "            X = torch.cat((X, x_new), dim=1)   # (B, T+1)\n",
    "        return X[0, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "710498e1-202f-4ebc-bdb0-a7b77a7bcd5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[310], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m GPT(config)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m batch \u001b[39m=\u001b[39m dataset[\u001b[39m0\u001b[39m:\u001b[39m3\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m logits, loss \u001b[39m=\u001b[39m model(batch[\u001b[39m0\u001b[39;49m], batch[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m      4\u001b[0m loss\n",
      "File \u001b[0;32m~/local/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/local/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[309], line 20\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     17\u001b[0m embeds \u001b[39m=\u001b[39m token_embeds \u001b[39m+\u001b[39m pos_embeds\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m---> 20\u001b[0m     embeds \u001b[39m=\u001b[39m block(embeds)\n\u001b[1;32m     22\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munembed(embeds)  \u001b[39m# (B, T, C)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m# tie the unembedding weights to the embedding weights\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m# linear function transposes the weight\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m#logits = fn.linear(embeds, self.token_embed.weight)\u001b[39;00m\n",
      "File \u001b[0;32m~/local/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/local/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[308], line 70\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln1 \u001b[39m=\u001b[39m fn\u001b[39m.\u001b[39mlayer_norm(X, X\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39mshape,X\u001b[39m.\u001b[39mweight)\n\u001b[1;32m     71\u001b[0m     X \u001b[39m=\u001b[39m X \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattend(X)\n\u001b[1;32m     72\u001b[0m     X \u001b[39m=\u001b[39m X \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeed(X)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "model = GPT(config).to(device)\n",
    "batch = dataset[0:3]\n",
    "logits, loss = model(batch[0], batch[1])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0b0677-1c22-4e76-9031-b05949807a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'^8HB2VMKA'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.decode( model.sample(8) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb7412-4a55-4d4c-af32-a9126a63f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c75ee-be50-4217-983c-2be18d3923a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.20it/s]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for step, batch in enumerate(dataset.loader):\n",
    "        X, Y = batch\n",
    "        # evaluate loss\n",
    "        logits, loss = model(X, Y)\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a7ca1-0106-4ab5-ada4-c6d8f94cef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9576235413551331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'^^^^^^^^^^^GCCGC$'"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(loss.item())\n",
    "dataset.decode( model.sample(16) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac2486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
